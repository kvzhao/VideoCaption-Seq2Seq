import os
import numpy as np

import tensorflow as tf
from tensorflow.contrib.data import Dataset, Iterator

from parser import FLAGS

def _pad_input(input_, size):
    return input_ + [0] * (size - len(input_))

def _downsample(features, interval):
    """
        Down sample the long time series 80/interval per feature
        use numpy slicing:
            https://stackoverflow.com/questions/25876640/subsampling-every-nth-entry-in-a-numpy-array
    """
    return features[::interval]

class IteratorInitializerHook(tf.train.SessionRunHook):
    """Hook to initialise data iterator after Session is created.
            https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook
        Another good reference
            https://medium.com/onfido-tech/higher-level-apis-in-tensorflow-67bfb602e6c0
    """

    def __init__(self):
        super(IteratorInitializerHook, self).__init__()
        self.iterator_initializer_func = None

    def after_create_session(self, session, coord):
        self.iterator_initializer_func(session)

def get_video_features(data_path, vid_path):
    with open(vid_path, "r") as f:
        # read lines and get rid of \n
        data_files = f.read().splitlines()

    features = []
    for feat_path in data_files:
        feats = np.load(os.path.join(data_path, feat_path) + ".npy")
        feats = _downsample(feats, FLAGS.down_sample)
        features.append(feats)
    return np.array(features, dtype=np.float32), data_files

def data_reader(data_path, vid_path, capid_path):
    """
        Args:
            data_path: Path to the 'training_data/feat'
            vid_path: File contains all video ids
            capid_path: File contains all caption token ids
            Both vid & capid are generated by preprocess_data.py
    """

    with open(vid_path, "r") as f:
        # read lines and get rid of \n
        data_files = f.read().splitlines()
    with open(capid_path, "rb") as f:
        label_files = [x.decode("utf-8").strip() for x in f.readlines()]
        #label_files = f.read().splitlines()

    # pad the captions!
    labels = []
    for line in label_files:
        ids = [int(id_) for id_ in line.split(" ")]
        ids = _pad_input(ids, FLAGS.max_seq_length)
        labels.append(ids)

    labels = np.array(labels, dtype=np.int32)

    #features = [np.load(os.path.join(data_path, feat_path) + ".npy") for feat_path in data_files]
    features = []
    for feat_path in data_files:
        feats = np.load(os.path.join(data_path, feat_path) + ".npy")
        feats = _downsample(feats, FLAGS.down_sample)
        features.append(feats)
    features = np.array(features, dtype=np.float32)

    print ("shape of the captions {}".format(labels.shape))
    print ("shape of the video features {}".format(features.shape))
    
    return features, labels

def get_train_inputs(features, captions):

    iterator_initializer_hook = IteratorInitializerHook()

    def train_inputs():
        with tf.name_scope("Train_Data"):
            #nonlocal X
            #nonlocal y

            input_placeholder = tf.placeholder(
                                tf.float32,
                                [None, FLAGS.max_video_length, FLAGS.frame_dim])
            output_placeholder = tf.placeholder(
                                tf.int32, [None, None])

            train_data = Dataset.from_tensor_slices(
                        (input_placeholder, output_placeholder))

            train_data = train_data.repeat(None)
            train_data = train_data.shuffle(buffer_size=1450)
            train_data = train_data.batch(FLAGS.batch_size)

            iterator = train_data.make_initializable_iterator()
            next_video, next_caption = iterator.get_next()

            # just give it the name
            tf.identity(next_video[0], "video_0")
            tf.identity(next_caption[0], "caption_0")

            # set runhook to initialize the iterator
            iterator_initializer_hook.iterator_initializer_func = \
                lambda sess: sess.run(iterator.initializer,
                    feed_dict={input_placeholder: features,
                                output_placeholder: captions})

            return next_video, next_caption
    return train_inputs, iterator_initializer_hook


def get_test_inputs(features, captions):

    iterator_initializer_hook = IteratorInitializerHook()

    def test_inputs():
        with tf.name_scope("Test_Data"):
            #nonlocal X
            #nonlocal y

            input_placeholder = tf.placeholder(
                                tf.float32,
                                [None, FLAGS.max_video_length, FLAGS.frame_dim])
            output_placeholder = tf.placeholder(
                                tf.int32, [None, None])

            test_data = Dataset.from_tensor_slices(
                        (input_placeholder, output_placeholder))

            test_data = test_data.repeat(None)
            test_data = test_data.shuffle(buffer_size=100)
            test_data = test_data.batch(FLAGS.batch_size)

            iterator = test_data.make_initializable_iterator()
            next_video, next_caption = iterator.get_next()

            # just give it the name
            tf.identity(next_video[0], "video_0")
            tf.identity(next_caption[0], "caption_0")

            # set runhook to initialize the iterator
            iterator_initializer_hook.iterator_initializer_func = \
                lambda sess: sess.run(iterator.initializer,
                    feed_dict={input_placeholder: features,
                                output_placeholder: captions})
            return next_video, next_caption

    return test_inputs, iterator_initializer_hook
